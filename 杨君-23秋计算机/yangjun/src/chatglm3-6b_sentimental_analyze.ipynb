{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45170a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (3.20.3)\n",
      "Requirement already satisfied: transformers>=4.30.2 in /opt/conda/lib/python3.10/site-packages (4.34.1)\n",
      "Collecting cpm_kernels\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/af/84/1831ce6ffa87b8fd4d9673c3595d0fc4e6631c0691eb43f406d3bf89b951/cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.10/site-packages (2.1.0+cu118)\n",
      "Collecting gradio\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/16/9b/46c017d6bbc60ccb13ef51af4b07dbb288b9080ea3170b8d47beee7842b6/gradio-4.10.0-py3-none-any.whl (16.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mdtex2html\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/47/fa/5156a032ad68f6c32ae0dc3aaf8b3d690004b42497d4735a08bb4cea6ec3/mdtex2html-1.2.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2.0) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.0) (2023.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0) (2.1.0)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/c5/e4/7fcceef127badbb0d644d730d992410e4f3799b295c9964a172f92a469c7/altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.9/996.9 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.104.1)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/9a/06/49b275a312eb207e2a2718a7414dedfded05088437352b67aaa9a355f948/ffmpy-0.3.1.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.7.3 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/78/52/a96eada27a2f711464c4a8c85a6110d46e35034cd2108640980c1fa4e8bb/gradio_client-0.7.3-py3-none-any.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.8/304.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a2/65/6940eeb21dcb2953778a6895281c179efd9100463ff08cb6232bb6480da7/httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/93/e8/facde510585869b5ec694e8e0363ffe4eba067cb357a8398a55f6a1f8023/importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.5.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/17/e2/7ff96963ba854f0a807fd2783bd7d947ecb0cac7df1d802699727c418aec/orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.1.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/0a/2b/64066de1c4cf3d4ed623beeb3bbf3f8d0cc26661f1e7d180ec5eb66b75a5/pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/b4/ff/b1e11d8bffb5e0e1b6d27f402eeedbeb9be6df2cdbc09356a1ae49806dbf/python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/68/4f/12207897848a653d03ebbf6775a29d949408ded5f99b2d87198bc5c93508/tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.24.0.post1)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.7.3->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/58/0a/7570e15661a0a546c3a1152d95fe8c05480459bab36247f0acbf41f01a41/websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from mdtex2html) (3.5.1)\n",
      "Collecting latex2mathml (from mdtex2html)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/f2/0a/181ed55562ce90179aedf33b09fcd79db31c868a5d480f3cb71a31d19692/latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/7f/5c/922a3508f5bda2892be3df86c74f9cf1e01217c2b1f8a0ac4841d903e3e9/toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.44.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Collecting pydantic-core==2.14.5 (from pydantic>=2.0->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/7c/f5/3e59681bd53955da311a7f4efbb6315d01006e9d18b8a06b527a22d3d923/pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers>=4.30.2)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/57/bd/45b5ef6b088880779f70acf60027f7043ca5fa1b98f4a4345cf3aea09044/tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/f7/fc/c55e5a2da345c9a24aa2e1e0f60eb2ca290b6a41be82da03a6d4baec4f99/accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/13/9e/ee987874058f2d93006961f6ff49e0bcb60ab9c26709ebe06bfa8707a4d8/accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d0/cf/364d550af711b5abe5129ac676896b223ba5a082d97fe400527a59c0c1f8/accelerate-0.24.0-py3-none-any.whl (260 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is still looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/d9/92/2d3aecf9f4a192968035880be3e2fc8b48d541c7128f7c936f430d6f96da/accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/4d/a7/05c67003d659a0035f2b3a8cf389c1d9645865aee84a73ce99ddab16682f/accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/f3/ef/da7601f3ec07cca00f535dc1bce93397fed30705d77e41df233db327c9c8/gradio-4.9.1-py3-none-any.whl (16.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/1e/f6/93fe8ff39a7387ac56b555547f3d6f154eeccd1b6fb87198b96f007d939c/gradio-4.9.0-py3-none-any.whl (16.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==0.7.2 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/28/f9/e9a1a40327bde4091a1a73f2a20c88bb95f108687cb32dc8949249c0e2c9/gradio_client-0.7.2-py3-none-any.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.6/304.6 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/67/bb/4a01345de5f30b897d8463921bf341a6dffcb5d73656a660e9e9160e2196/gradio-4.8.0-py3-none-any.whl (16.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==0.7.1 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/2e/9e/ce7b34549e418cb7a1c1b541cf5f108f32be08e9ef31eb061fc5218c0091/gradio_client-0.7.1-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.30.2)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.30.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.30.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.30.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.30.2) (2023.7.22)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\n",
      "Collecting httpcore==1.* (from httpx->gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5593 sha256=df7dcb5a2da7a7954a424266339bc76eac9e7955afaf03f80d7f8032936918b6\n",
      "  Stored in directory: /root/.cache/pip/wheels/82/87/0f/849e4ae8ec7a67d7a27c8f8ec9bc60f46bde4863fb76e02555\n",
      "Successfully built ffmpy\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pydub, ffmpy, cpm_kernels, websockets, toolz, tomlkit, shellingham, semantic-version, python-multipart, pydantic-core, orjson, latex2mathml, importlib-resources, httpcore, aiofiles, pydantic, mdtex2html, huggingface-hub, httpx, gradio-client, altair, gradio\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 12.0\n",
      "    Uninstalling websockets-12.0:\n",
      "      Successfully uninstalled websockets-12.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.3\n",
      "    Uninstalling pydantic_core-2.14.3:\n",
      "      Successfully uninstalled pydantic_core-2.14.3\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.13\n",
      "    Uninstalling pydantic-1.10.13:\n",
      "      Successfully uninstalled pydantic-1.10.13\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.19.4\n",
      "    Uninstalling huggingface-hub-0.19.4:\n",
      "      Successfully uninstalled huggingface-hub-0.19.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.15.0 requires huggingface-hub>=0.18.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "vllm 0.2.1+cu118torch2.1 requires pydantic==1.10.13, but you have pydantic 2.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.2.1 altair-5.2.0 cpm_kernels-1.0.11 ffmpy-0.3.1 gradio-4.8.0 gradio-client-0.7.1 httpcore-1.0.2 httpx-0.25.2 huggingface-hub-0.17.3 importlib-resources-6.1.1 latex2mathml-3.77.0 mdtex2html-1.2.0 orjson-3.9.10 pydantic-2.5.2 pydantic-core-2.14.5 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 tomlkit-0.12.0 toolz-0.12.0 websockets-11.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf 'transformers>=4.30.2' cpm_kernels 'torch>=2.0' gradio mdtex2html sentencepiece accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06017f2b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 模型下载\n",
    "modelscope API下载\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2bc3523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: modelscope in /opt/conda/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from modelscope) (23.1.0)\n",
      "Requirement already satisfied: datasets>=2.14.5 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.15.0)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.7.0)\n",
      "Requirement already satisfied: filelock>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (3.13.1)\n",
      "Requirement already satisfied: gast>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.5.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.26.1)\n",
      "Requirement already satisfied: oss2 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.18.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.1.3)\n",
      "Requirement already satisfied: Pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (10.1.0)\n",
      "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (14.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from modelscope) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.25 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.31.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.11.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from modelscope) (68.0.0)\n",
      "Requirement already satisfied: simplejson>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (3.19.2)\n",
      "Requirement already satisfied: sortedcontainers>=1.5.9 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (4.65.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.26.16)\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.30.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.5->modelscope) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.5->modelscope) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.5->modelscope) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.5->modelscope) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets>=2.14.5->modelscope) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.5->modelscope) (3.9.1)\n",
      "Collecting huggingface-hub>=0.18.0 (from datasets>=2.14.5->modelscope)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.14.5->modelscope) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.1->modelscope) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (2023.7.22)\n",
      "Requirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope) (1.7)\n",
      "Requirement already satisfied: pycryptodome>=3.4.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope) (3.19.0)\n",
      "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope) (2.16.2)\n",
      "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope) (2.14.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope) (2023.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (0.10.0)\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (41.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets>=2.14.5->modelscope) (4.8.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (2.21)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.19.4 which is incompatible.\n",
      "vllm 0.2.1+cu118torch2.1 requires pydantic==1.10.13, but you have pydantic 2.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.19.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install modelscope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d8559",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd4ba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 15:38:06,209 - modelscope - INFO - PyTorch version 2.1.0+cu118 Found.\n",
      "2023-12-17 15:38:06,213 - modelscope - INFO - TensorFlow version 2.14.0 Found.\n",
      "2023-12-17 15:38:06,213 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-12-17 15:38:06,214 - modelscope - INFO - No valid ast index found from /mnt/workspace/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
      "2023-12-17 15:38:06,282 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 44f0b88effe82ceea94a98cf99709694 and a total number of 946 components indexed\n",
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-17 15:38:08,002 - modelscope - INFO - Use user-specified model revision: v1.0.0\n",
      "Downloading: 100%|██████████| 1.29k/1.29k [00:00<00:00, 4.60MB/s]\n",
      "Downloading: 100%|██████████| 40.0/40.0 [00:00<00:00, 183kB/s]\n",
      "Downloading: 100%|██████████| 2.28k/2.28k [00:00<00:00, 8.96MB/s]\n",
      "Downloading: 100%|██████████| 4.04k/4.04k [00:00<00:00, 7.51MB/s]\n",
      "Downloading: 100%|██████████| 54.3k/54.3k [00:00<00:00, 60.0MB/s]\n",
      "Downloading: 100%|█████████▉| 1.70G/1.70G [00:06<00:00, 279MB/s]\n",
      "Downloading: 100%|█████████▉| 1.83G/1.83G [00:07<00:00, 272MB/s]\n",
      "Downloading: 100%|█████████▉| 1.80G/1.80G [00:07<00:00, 265MB/s]\n",
      "Downloading: 100%|█████████▉| 1.69G/1.69G [00:07<00:00, 239MB/s]\n",
      "Downloading: 100%|█████████▉| 1.83G/1.83G [00:07<00:00, 261MB/s]\n",
      "Downloading: 100%|█████████▉| 1.80G/1.80G [00:08<00:00, 220MB/s]\n",
      "Downloading: 100%|█████████▉| 0.98G/0.98G [00:05<00:00, 189MB/s]\n",
      "Downloading: 100%|██████████| 20.0k/20.0k [00:00<00:00, 27.2MB/s]\n",
      "Downloading: 100%|██████████| 14.3k/14.3k [00:00<00:00, 20.2MB/s]\n",
      "Downloading: 100%|██████████| 4.37k/4.37k [00:00<00:00, 5.45MB/s]\n",
      "Downloading: 100%|██████████| 11.0k/11.0k [00:00<00:00, 15.8MB/s]\n",
      "Downloading: 100%|██████████| 995k/995k [00:00<00:00, 38.3MB/s]\n",
      "Downloading: 100%|██████████| 244/244 [00:00<00:00, 1.37MB/s]\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download(\"ZhipuAI/chatglm3-6b\", revision = \"v1.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d69bd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 代码调用 \n",
    "\n",
    "可以通过如下代码调用 ChatGLM3-6B 模型来生成对话：\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f10c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 15:39:58.352151: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-17 15:39:58.352198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-17 15:39:58.352227: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-17 15:39:58.362008: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-17 15:39:59.682749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-17 15:40:00,772 - modelscope - INFO - Use user-specified model revision: v1.0.0\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:10<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。\n",
      "晚上睡不着可以尝试以下方法：\n",
      "\n",
      "1. 保持冷静：睡前不要过度紧张，避免思考烦恼的事情，可以尝试进行深呼吸、听轻音乐等放松身心的方法。\n",
      "\n",
      "2. 创造良好的睡眠环境：保持卧室安静、舒适、黑暗。避免使用电子设备，如手机、电脑等带有蓝光的设备，因为蓝光会干扰褪黑激素的分泌，影响睡眠质量。\n",
      "\n",
      "3. 规律作息：保持规律的作息时间，每天尽量在相同的时间上床睡觉和起床。\n",
      "\n",
      "4. 适当运动：白天进行适当运动，如散步、瑜伽等，有助于晚上更好地入睡。\n",
      "\n",
      "5. 饮食调整：避免睡前过量饮食，不要吃辛辣、油腻等刺激性食物。\n",
      "\n",
      "6. 尝试放松技巧：如冥想、按摩、阅读等，有助于缓解压力，提高睡眠质量。\n",
      "\n",
      "如果长时间睡不着，建议寻求专业医生的帮助。\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoTokenizer, AutoModel, snapshot_download\n",
    "model_dir = snapshot_download(\"ZhipuAI/chatglm3-6b\", revision = \"v1.0.0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_dir, trust_remote_code=True).half().cuda()\n",
    "model = model.eval()\n",
    "response, history = model.chat(tokenizer, \"你好\", history=[])\n",
    "print(response)\n",
    "response, history = model.chat(tokenizer, \"晚上睡不着应该怎么办\", history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd786d85-b3e5-4621-9be1-2141b48b0c0c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 情感分析 - Zero-Shot prompt\n",
    "\n",
    "可以通过如下代码进行情感分析:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f0d3cb2-9cfa-4b64-8ebb-9cf43a3e2aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "负面的\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"你是一个情感分析专家。请判断以下句子的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "\n",
    "给出的句子是：\n",
    "弱到爆…剧情、氛围烘托、表演、服化道、特效，统统弱到爆！女主和哥哥转折超级无力，给女主默默烫发来表现阶段性\n",
    "转折也是醉了…，除了小迅猛龙看起来像狗以外，其余真是…吐槽无力\n",
    "\n",
    "回答：\n",
    "\"\"\"\n",
    "\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f77d9e32-942f-4583-a55b-e8b13319093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这句话的情感中包含了一些负面情感，比如“男主没那么帅到爆”，“女有那么一点骚气”，以及“我喜欢，总体还可以，但是也平庸”。所以，这句话的情感可以判断为 ['负面的', '中性的']。\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"你是一个情感分析专家。请判断以下句子的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "\n",
    "给出的句子是：\n",
    "男主没那么帅到爆，女有那么一点骚气，我喜欢，总体还可以，但是也平庸。\n",
    "\n",
    "回答：\n",
    "\"\"\"\n",
    "\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daf64bf5-d9ec-4d5f-b30c-276d27aaf0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['正面的']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"你是一个情感分析专家。请判断以下句子的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "\n",
    "给出的句子是：\n",
    "我今天中午吃了玉米排骨汤和红烧肉\n",
    "\n",
    "回答：\n",
    "\"\"\"\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b86b0b3-34f7-4294-90eb-81dd58748edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['正面的', '积极的']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"你是一个情感分析专家。请判断以下句子的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "\n",
    "给出的句子是：\n",
    "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
    "\n",
    "回答：\n",
    "\"\"\"\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b2918-8996-4c65-b940-b39fec65d504",
   "metadata": {},
   "source": [
    "\n",
    "## 情感分析 - Few-Shot prompt\n",
    "\n",
    "可以通过如下代码进行Few-Shot prompt优化后，对评论文本进行情感分析:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1d9a9ad-1943-4f99-82f9-4d224fc7e8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出列表：[\"正面的\"]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"你是一个情感分析专家。你应该判断一整段话的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "如果不存在，回答：没有。\n",
    "返回结果为输出列表。\n",
    "\n",
    "下面是一些例子\n",
    "\"值得去的地方，石头很奇特，景色优美，环境宜人，适合与朋友家人一起游玩\"  ->  [\"正面的\"]\n",
    "\"弱到爆…剧情、氛围烘托、表演、服化道、特效，统统弱到爆！女主和哥哥转折超级无力，给女主默默烫发来表现阶段性\n",
    "转折也是醉了…，除了小迅猛龙看起来像狗以外，其余真是…吐槽无力\"  ->  [\"负面的\"]\n",
    "\"Adrian Pasdar is excellent is this film. He makes a fascinating woman.\"  ->  [\"正面的\"]\n",
    "\"This movie is terrible but it has some good effects.\" ->  [\"负面的\"]\n",
    "\"我今天中午吃了玉米排骨汤和红烧肉\"    ->  没有\n",
    "\n",
    "\n",
    "你应该判断该句子的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "输出列表：[\"正面的\"]\n",
    "如果不存在，回答：没有。\n",
    "返回结果为输出列表。\n",
    "\n",
    "\n",
    "现在，我给你一段话:\n",
    "\"I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\"\n",
    "你应该判断这段话的情感倾向，并以列表的形式返回结果，如果不存在，则回答：没有。\n",
    "\"\"\"\n",
    "\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecee1adf-e89b-4606-ae89-bf9f3a9ac1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该句子与情感分析相关的问题无关。请提供与情感分析相关的问题，我会尽力帮助您。\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"你是一个情感分析专家。你应该判断该句子的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "如果不存在，回答：没有。\n",
    "返回结果为输出列表。\n",
    "\n",
    "下面是一些例子\n",
    "\"值得去的地方，石头很奇特，景色优美，环境宜人，适合与朋友家人一起游玩\"  ->  [\"正面的\"]\n",
    "\"弱到爆…剧情、氛围烘托、表演、服化道、特效，统统弱到爆！女主和哥哥转折超级无力，给女主默默烫发来表现阶段性\n",
    "转折也是醉了…，除了小迅猛龙看起来像狗以外，其余真是…吐槽无力\"  ->  [\"负面的\"]\n",
    "\"Adrian Pasdar is excellent is this film. He makes a fascinating woman.\"  ->  [\"正面的\"]\n",
    "\"This movie is terrible but it has some good effects.\" ->  [\"负面的\"]\n",
    "\"我今天中午吃了玉米排骨汤和红烧肉\"    ->  没有\n",
    "\n",
    "\n",
    "你应该判断该句子的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "输出列表：[\"正面的\"]\n",
    "如果不存在，回答：没有。\n",
    "返回结果为输出列表。\n",
    "\n",
    "\n",
    "现在，我给你一个句子:\n",
    "\"我今天中午吃了玉米排骨汤和红烧肉\"\n",
    "你应该判断句子的情感倾向，并以列表的形式返回结果，如果不存在，则回答：没有。\n",
    "\"\"\"\n",
    "\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4420889-3ac3-401c-9b9b-c8627acdbf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该句子的情感倾向是['负面的']。\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"你是一个情感分析专家。你应该判断该句子的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "如果不存在，回答：没有。\n",
    "返回结果为输出列表。\n",
    "\n",
    "下面是一些例子\n",
    "\"值得去的地方，石头很奇特，景色优美，环境宜人，适合与朋友家人一起游玩\"  ->  [\"正面的\"]\n",
    "\"弱到爆…剧情、氛围烘托、表演、服化道、特效，统统弱到爆！女主和哥哥转折超级无力，给女主默默烫发来表现阶段性\n",
    "转折也是醉了…，除了小迅猛龙看起来像狗以外，其余真是…吐槽无力\"  ->  [\"负面的\"]\n",
    "\"Adrian Pasdar is excellent is this film. He makes a fascinating woman.\"  ->  [\"正面的\"]\n",
    "\"This movie is terrible but it has some good effects.\" ->  [\"负面的\"]\n",
    "\"我今天中午吃了玉米排骨汤和红烧肉\"    ->  没有\n",
    "\n",
    "\n",
    "你应该判断该句子的情感是什么，情感从['正面的', '负面的', '中性的']里选择。\n",
    "输出列表：[\"正面的\"]\n",
    "如果不存在，回答：没有。\n",
    "返回结果为输出列表。\n",
    "\n",
    "\n",
    "现在，我给你一个句子:\n",
    "\"Widow hires a psychopath as a handyman. Sloppy film noir thriller which doesn't make much of its tension promising set-up. (3/10)\"\n",
    "你应该判断句子的情感倾向，并以列表的形式返回结果，如果不存在，则回答：没有。\n",
    "\"\"\"\n",
    "\n",
    "response, history = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16143d93-aa42-4dd8-8169-be58d77c8153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
